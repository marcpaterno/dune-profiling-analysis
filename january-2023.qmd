---
title: "Investigating PDFastSimPAR"
author: "Marc Paterno"
institute: "Fermi National Accelerator Laboratory"
date: last-modified
date-format: long
format:
  html:
    theme: plain
  beamer:
    theme: MFP
    pdf-engine: xelatex
    mainfont: Geneva
    aspectratio: 169
---

```{r, setup, include=FALSE}
library(tidyverse)
```

## Why this work?

* Goal is to accelerate DUNE physics processing using GPUs, for some algorithm in LArSoft.
This aligns with the LArSoft "high priority" goal list.
* Multi-step process:

    #. Identify a likely candidate module from LArSoft.\footnote{Thank you to Tom Junk and Laura Paulucci for their guidance.}
    #. Collect performance data to see where the code is taking the most time.
    #. Improve the \alert{serial} algorithm performance.
    #. \alert{Parallelize} the serial algorithm.
    #. If the result is still insufficient, adapt the parallel algorithm for \alert{GPU usage}.
* `PDFastSimPAR` was the clear most time-consuming module used in the DUNE workflows that is found in LArSoft.

## Workflow based on a standard DUNE FD simulation workflows

`lar` configurations:

* `prodbackground_radiological_decay0_dunevd10kt_1x8x14.fcl`
* `prodmarley_nue_flat_radiological_decay0_dunevd10kt_1x8x14_3view_30deg.fcl`

Geant4 simulation as input:

* `/pnfs/dune/persistent/users/lpaulucc/leprodtests/`
  `prodradiological_decay0_dunevd10kt_1x8x14_gen.root`

Break the workflow into two parts:

* Everything \alert{before} the `PDFastSimPAR` module, which I write to an art/ROOT file, and
* The `PDFastSimPAR` module run alone, on the output from the previous step.

## Profiling data collection

* I am using the Intel VTune performance analysis suite of tools.
* Running an `opt` build on a SLF7 Linux machine.
* Hardware is Skylake AVX512
* Standard `opt` build does \alert{not} activate the compiler options to make full use of the instruction set.
Essentially no automatic vectorization is done.
* VTune collects a huge amount of data; I run on only 1 event to keep the data analysis feasible.
* Happily, previous analysis shows that the time taken to process events in the given file is very uniform.

## First profiling results

* Biggest hotspot in LArSoft code is `phot::fast_acos`, for a total of 7.111 seconds (out of 48.220 seconds in `PDFastSimPAR::produce`).
* Called from two places within the code.

## `phot::fast_acos`

* Implementation from *Approximations for Digital Computers*, C. Hastings, Jr, published by Princeton University Press (1955), with flourishes that seem to be related to an implementation posted by NVIDIA.
* Invented before computers had instruction sets that included trig functions.
* Invented before the IEEE floating point standard was devised.
* Do we need such a thing today?

## Microbenchmarking results

* Data collected on the same machine as used for VTune results.

| ns/op | err% | ins/op | bra/op | acos tests
|------:|-----:|-------:|-------:|:-----------
| 12.36 | 0.0% |  85.00 |   9.00 | `fast_acos`
| 34.80 | 2.8% | 217.00 |  35.00 | `acos(double)`
| 20.29 | 0.3% | 114.00 |  20.00 | `acos(float)`

* `fast_acos` is clearly faster than even the single-precision math library function.
* Less time per operation, because of fewer instructions and fewer branches encountered.

## `phot::fast_acos` shape of the curve

```{r, include=FALSE}
x <- read_tsv("acos.tsv")
x <- mutate(x,
            diff = std-fast,
            fracdiff = abs(diff)/std)
```

```{r, echo=FALSE}
#| fig-height: 4.5
ggplot(x) +
  #geom_point(mapping=aes(x, std), color = "magenta") +
  geom_point(mapping=aes(x, fast), color = "cyan") +
  labs(x="x", y="fast_acos")
```

## `phot::fast_acos` difference from C library

```{r, echo = FALSE}
#| fig-height: 4.5
ggplot(x, aes(x, diff)) +
  geom_point(size=0.1) +
  labs(x="x", y = "std::acos(double) - fast_acos")
```

## `phot::fast_acos` relative difference from C library

```{r, echo=FALSE}
#| fig-height: 4.5
ggplot(x, aes(x, fracdiff)) +
  geom_point(size=0.1) +
  labs(x="x", y="|fractional difference|")
```

## Is `phot::fast_acos` sufficiently accurate?

* If not, then replacing it with `std::acos` is trivial; the cost is a factor of 60% in speed.
* If yes, then I have some modifications that yield identical results, and about a 40% speed improvement.

## New implementation: `hastings_acos`

| ns/op |  err% | ins/op | bra/op | acos tests
|------:|------:|-------:|-------:|:-----------
| 12.36 |  0.0% |  85.00 |   9.00 | `fast_acos`
|  7.04 |  0.7% |  57.00 |   8.00 | `hastings_acos`

* The significant code change is undoing the "flourishes" that are appropriate for GPU usage, but are counterproductive on CPUs.
* Used in context, VTune reports 4.240 seconds spent in the new algorithm (compare with 7.111 seconds from the original),
* `PDFastSimPAR::produce` now takes 44.280 seconds (compare with 48.220 seconds).

## Various `acos` outputs: zoomed in near x=0.5

```{r, echo=FALSE}
#| fig-height: 4.5
filter(x, x>0.4995, x< 0.5005) |>
  ggplot() +
    geom_point(mapping=aes(x, std), color = "magenta") +
    geom_point(mapping=aes(x, fast), color = "cyan") +
    geom_line(mapping=aes(x, stdf), color = "red") +
    geom_line(mapping=aes(x, hastings), color = "green") +
    labs(x="x",
         y="cyan: fast_acos\nmagenta: std::acos(double)\nred line:std::acos(float)\ngreen line:hastings")
```

