---
title: "Investigating PDFastSimPAR"
author: "Marc Paterno"
institute: "Fermi National Accelerator Laboratory"
date: last-modified
date-format: long
format:
  html:
    theme: plain
  beamer:
    theme: MFP
    pdf-engine: xelatex
    mainfont: Geneva
    aspectratio: 169
---

```{r, setup, include=FALSE}
library(tidyverse)
```

## Why this work?

* Goal is to accelerate DUNE physics processing using GPUs, for some algorithm in LArSoft.
This aligns with the LArSoft "high priority" goal list.
* Multi-step process:

    #. Identify a likely candidate module from LArSoft.\footnote{Thank you to Tom Junk and Laura Paulucci for their guidance.}
    #. Collect performance data to see where the code is taking the most time.
    #. Improve the \alert{serial} algorithm performance.
    #. \alert{Parallelize} the serial algorithm.
    #. If the result is still insufficient, adapt the parallel algorithm for \alert{GPU usage}.
* `PDFastSimPAR` was the clear most time-consuming module used in the DUNE workflows that is found in LArSoft.

## Workflow based on a standard DUNE FD simulation workflows

`lar` configurations:

* `prodbackground_radiological_decay0_dunevd10kt_1x8x14.fcl`
* `prodmarley_nue_flat_radiological_decay0_dunevd10kt_1x8x14_3view_30deg.fcl`

Geant4 simulation as input:

* `/pnfs/dune/persistent/users/lpaulucc/leprodtests/`
  `prodradiological_decay0_dunevd10kt_1x8x14_gen.root`

Break the workflow into two parts:

* Everything \alert{before} the `PDFastSimPAR` module, which I write to an art/ROOT file, and
* The `PDFastSimPAR` module run alone, on the output from the previous step.

## Profiling data collection

* I am using the Intel VTune performance analysis suite of tools.
* Running an `opt` build on a SLF7 Linux machine.
* Hardware is Skylake AVX512
* Standard `opt` build does \alert{not} activate the compiler options to make full use of the instruction set.
Essentially no automatic vectorization is done.
* VTune collects a huge amount of data; I run on only 1 event to keep the data analysis feasible.
* Happily, previous analysis shows that the time taken to process events in the given file is very uniform.

## First profiling results

* Biggest hotspot in LArSoft code is `phot::fast_acos`, for a total of 7.111 seconds (out of 48.220 seconds in `PDFastSimPAR::produce`).
* Called from two places within the code.

## `phot::fast_acos`

* Implementation from *Approximations for Digital Computers*, C. Hastings, Jr, published by Princeton University Press (1955).
* Invented before computers had instruction sets that included trig functions.
* Invented before the IEEE floating point standard was devised.

## `phot::fast_acos` shape of the curve

```{r, include=FALSE}
x <- read_tsv("acos.tsv")
x <- mutate(x,
            diff = std-fast,
            fracdiff = abs(diff)/std)
```

```{r, echo=FALSE}
#| fig-height: 4.5
ggplot(x) +
  #geom_point(mapping=aes(x, std), color = "magenta") +
  geom_point(mapping=aes(x, fast), color = "cyan") +
  labs(x="x", y="fast_acos")
```

## `phot::fast_acos` shape: zoomed in near x=0.5

```{r, echo=FALSE}
#| fig-height: 4.5
filter(x, x>0.4995, x< 0.5005) |>
  ggplot() +
    geom_point(mapping=aes(x, std), color = "magenta") +
    geom_point(mapping=aes(x, fast), color = "cyan") +
    geom_line(mapping=aes(x, stdf), color = "red") +
    geom_line(mapping=aes(x, hastings), color = "green") +
    labs(x="x",
         y="cyan: fast_acos\nmagenta: std::acos(double)\nred line:std::acos(float)\ngreen line:hastings")
```

## `phot::fast_acos` difference from C library

```{r, echo = FALSE}
#| fig-height: 4.5
ggplot(x, aes(x, diff)) +
  geom_point(size=0.1) +
  labs(x="x", y = "std::acos(float) - fast_acos")
```

## `phot::fast_acos` relative difference from C library

```{r, echo=FALSE}
#| fig-height: 4.5
ggplot(x, aes(x, fracdiff)) +
  geom_point(size=0.1) +
  labs(x="x", y="|fractional difference|")
```

## Is `phot::fast_acos` sufficiently accurate?

* If not, then replacing it with `std::acos` is trivial; the cost is a factor of ~4 in speed.
* If yes, then replacing it with `hastings_acos` yields identical results, and about a 30% speed improvement.
